---
title: "models_tests"
author: "Marc"
date: "25/2/2022"
output: 
  html_document:
    theme: united
    code_folding: hide
    toc: true
    toc_depth: 2 
editor_options: 
  chunk_output_type: console
---

# Libraries

```{r include=FALSE}
library(ggplot2)
library(ggfortify)
library(plotly)
library(cowplot)
library(caret)
library(readr)
library(tidyr)
library(dplyr)
library(purrr)
library(ggrepel)
library(patchwork)
theme_set(theme_minimal())
```


```{r}
plot_pca <- function(tmp1, tmp2, color_label, ranks = 10){
  
  tmp3 <- prcomp(tmp2, center = T, scale. = T, rank. = ranks)

  pdata <- 
    tmp3$x %>% 
    as_tibble() %>% 
    bind_cols(tmp1 %>% select(all_of(color_label)) %>% mutate_all(as.factor)) %>% 
    pivot_longer(cols = seq(1, ncol(.)-length(color_label), by=2)) %>% 
    select(x_val = value, x_name = name, everything()) %>% 
    pivot_longer(cols = starts_with("PC")) %>% 
    select(x_name, y_name = name,x_val, y_val = value, everything()) %>%
    mutate(name = paste(x_name, "vs", y_name),
           name = factor(name, levels = sort(name) %>% unique())) %>% 
    filter(as.numeric(gsub("PC", "", x_name)) + 1 == as.numeric(gsub("PC", "", y_name)))
  
  pca_plot <- pdata %>% 
    ggplot(aes(x=x_val, y=y_val))+
    geom_point(aes_string(fill = color_label), shape = 21, color = "white")+
    facet_grid(~name, scales = "free")+
    labs(x = "", y = "")+
    NULL
  return(pca_plot)
}

```


# Data loading

```{r}
#setwd("../workflowr/data")
mdf <- read_csv("TraceAge_bloodspots_t3_pos_clean.csv")

#mdf<-mdf %>% gather(key="mz",value="values",6:ncol(mdf)) %>% spread(mz,values)
```

# Simplest model ever

## No transformation or BN is performed in this data

## PCAs for data visualization

```{r}
pca_df<-mdf %>% filter(type=="sample")
pr.out <- prcomp(pca_df[,6:(ncol(mdf))], scale. = TRUE)
```

### Scree Plot

```{r}
var_explained_df <- data.frame(PC= as.numeric(paste0(1:150)),
                               var_explained=(pr.out$sdev)^2/sum((pr.out$sdev)^2))

var_explained_df %>%
  ggplot(aes(x=PC,y=var_explained, group=1))+
  geom_point()+
  geom_line()+
  labs(title="Scree plot: PCA on scaled data")

var_explained_df %>%
  ggplot(aes(x=PC,y=var_explained))+
  geom_col()+
  labs(title="Scree plot: PCA on scaled data")

sum(var_explained_df$var_explained[1:11])
```

### Plotting the first 12 PCs since they explain \~65% of the data

```{r}
p1<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 1, y =2)
p2<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 3, y =4)
p3<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 5, y =6)
p4<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 7, y =8)
p5<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 9, y =10)
p6<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 11, y =12)

cowplot::plot_grid(p1,p2,p3,p4,p5,p6)
```

### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```

## Make a Training/Test from the data and try regression on age

```{r}
training_DF <- mdf %>% select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age
```

## Choosing a good model to make the comparisons and storing the RMSE somehow

```{r eval=FALSE, warning=FALSE, include=FALSE}
#Making an empty DF
tunelengths <- data.frame(TrainRMSE = as.numeric(),TrainRsquared = as.numeric(),TrainMAE = as.numeric(),method = as.character(),Name = as.character(),QC = as.character())

#Making a loop to choose the best tunelength (This method could also be applied if I decide to try different models, and I want to compare them)
set.seed(1)
for (i in c(1:15)){
trControl <- trainControl(method = "repeatedcv", number = 10, verboseIter = F, savePredictions = "final")
  
fit1 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = i,
       trControl = trControl,
       metric = 'RMSE'
      )
tunelengths[i-1,] = data.frame(getTrainPerf(fit1), Name = paste0("tunelength", i-1), QC = "none")
}

tunelengths
```

The tuneLength doesn't make the RMSE change much. I will stay with GLMNET and a tunelength of 5.

## Making a simple model and storing the RMSE

```{r}
results <- data.frame(TrainRMSE = as.numeric(),TrainRsquared = as.numeric(),TrainMAE = as.numeric(),method = as.character(),Name = as.character(),QC = as.character())

trControl <- trainControl(method = "repeatedcv", number = 10, verboseIter = F, savePredictions = "final")

fit1 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[1,] = data.frame(getTrainPerf(fit1), Name = paste0("fit1"), QC = "none")
```

# Model with 4th root transformed data

## 4th root transformation

```{r}
#Imputing zeros
test_df<-mdf %>% gather(key="mz",value="values",6:ncol(mdf))
test_df$values[is.na(test_df$values)] <- 0
#4th root transformation

root_transform <- function(x){
  return (x^0.25)}
mdf[6:(ncol(mdf))] <- lapply(mdf[6:(ncol(mdf))],root_transform)
```

## PCAs for data visualization

```{r}
pca_df<-mdf %>% filter(type=="sample")
pr.out <- prcomp(pca_df[,6:(ncol(mdf))], scale. = TRUE)
```


### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)
test<-data.frame(r$x)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```

## Make a Training/Test from the data and try regression on age

```{r}
training_DF <- mdf %>% select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age
```

## Making the model model and storing the RMSE

```{r}
trControl <- trainControl(method = "repeatedcv", number = 10, verboseIter = F, savePredictions = "final")

fit2 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[2,] = data.frame(getTrainPerf(fit2), Name = paste0("fit2"), QC = "4th_root")

results
```

# Model with PCA outliers removed

## Alternative method using boxplot information
One method I found of removing PCA outliers without using quantiles is using the boxplot function. 
https://www.r-bloggers.com/2020/01/how-to-remove-outliers-in-r/
```{r}
#This is a boxplot of the outliers on the PCs

boxplot(r$x)$out

#We can save the outliers on a vector
outliers <- boxplot(r$x, plot = F)$out

#This can be easily removed from the PCA file, but I'm not sure how I can get the rowid from them to remove them from the original dataframe
x<-r$x
plot(x)
x<- x[-which(x[,ncol(x)] %in% outliers),]
#☝️ still I think it doesn't quite work because it removes three rows but when plotted the results look it has removed something, but not the outliers :/
plot(x)
```

## Original method using quantiles
I haven't found any package that does it automatically, meaning I will have to explain a bit the theory behind this method. 
https://www.r-bloggers.com/2021/09/how-to-remove-outliers-in-r-3/

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}


bad_rows <- tmp1 %>% filter(n>0)
ms = list()
if (nrow(bad_rows) > 0) {
  ms$values1  <- raw[-bad_rows$rowid,]
  ms$rowinfo1 <- rowinfo[-bad_rows$rowid,]
} else {
  ms$values1  <- raw
  ms$rowinfo1 <- rowinfo
}

ms$rowinfo1 <- ms$rowinfo1 %>% 
  mutate(rowid = row_number()) 

rm(bad_rows, tmp1, tmp2,r)

tmp1 <- ms$rowinfo1 %>% filter(type %in% c("sample"))
tmp2 <- ms$values1[tmp1$rowid,]
plot_pca(tmp1,tmp2,color_label = "age")
rm(tmp1,tmp2)
```

## Model code
```{r}

target_info   <- ms$rowinfo1
target_values <- ms$values1

x <- target_info %>% 
    filter(type=="sample")

training_DF <- x %>% 
  select(age) %>% 
  bind_cols(target_values[x$rowid,])
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age

trControl <- trainControl(method = "repeatedcv", number = 10, verboseIter = F, savePredictions = "final")

fit3 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[3,] = data.frame(getTrainPerf(fit3), Name = paste0("fit3"), QC = "4th_root + PCA outlier removal")

results
```


# Model after removing extreme values

(values larger than median + 1.5 * q90)
```{r eval=FALSE, include=FALSE}
# raw     <- ms$values1
# rowinfo <- ms$rowinfo1
# 
# tmp1 <- tibble(rowid = rowinfo$rowid, type = rowinfo$type) %>%
#   bind_cols(as_tibble(raw))
# 
# tmp1 <- tmp1 %>% 
#   pivot_longer(names_to = "compound", values_to = "value",  cols= c(-rowid, -type))
# 
# tmp2 <- tmp1 %>%
#  group_by(compound) %>%
#  summarise(n_bad = sum(value > median(value)+1.5*quantile(value,0.90))) %>%
#  {.}
# 
# bad_features <- tmp2 %>% 
#   ungroup() %>%
#   filter(n_bad > 0) %>%
#   select(compound) %>%
#   distinct()
# 
# ms$values2 <- raw %>% select(-any_of(bad_features$compound))
# ms$rowinfo2 <- rowinfo
# 
# rm(bad_features,tmp2,tmp1,raw)
# 
# tmp1 <- ms$rowinfo2 %>% filter(type %in% c("sample"))
# tmp2 <- ms$values2[tmp1$rowid,]
# plot_pca(tmp1,tmp2,color_label = "age")
```


# Model after removing features using QC and blind samples. 
