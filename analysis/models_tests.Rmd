---
title: "models_tests"
author: "Marc"
date: "25/2/2022"
output: 
  html_document:
    theme: united
    code_folding: hide
    toc: true
    toc_depth: 2 
editor_options: 
  chunk_output_type: console
---

# Libraries

```{r include=FALSE}
library(ggplot2)
library(ggfortify)
library(plotly)
library(cowplot)
library(caret)
library(readr)
library(tidyr)
library(dplyr)
library(purrr)
library(ggrepel)
library(patchwork)
theme_set(theme_minimal())
```

```{r}
plot_pca <- function(tmp1, tmp2, color_label, ranks = 10){
  
  tmp3 <- prcomp(tmp2, center = T, scale. = T, rank. = ranks)

  pdata <- 
    tmp3$x %>% 
    as_tibble() %>% 
    bind_cols(tmp1 %>% select(all_of(color_label)) %>% mutate_all(as.factor)) %>% 
    pivot_longer(cols = seq(1, ncol(.)-length(color_label), by=2)) %>% 
    select(x_val = value, x_name = name, everything()) %>% 
    pivot_longer(cols = starts_with("PC")) %>% 
    select(x_name, y_name = name,x_val, y_val = value, everything()) %>%
    mutate(name = paste(x_name, "vs", y_name),
           name = factor(name, levels = sort(name) %>% unique())) %>% 
    filter(as.numeric(gsub("PC", "", x_name)) + 1 == as.numeric(gsub("PC", "", y_name)))
  
  pca_plot <- pdata %>% 
    ggplot(aes(x=x_val, y=y_val))+
    geom_point(aes_string(fill = color_label), shape = 21, color = "white")+
    facet_grid(~name, scales = "free")+
    labs(x = "", y = "")+
    NULL
  return(pca_plot)
}

```

# Data loading

```{r}
#setwd("../workflowr/data")
mdf <- read_csv("TraceAge_bloodspots_t3_pos_clean.csv")

#mdf<-mdf %>% gather(key="mz",value="values",6:ncol(mdf)) %>% spread(mz,values)
```

# Simplest model ever

No transformation or BN is performed in this data

## PCAs for data visualization

```{r}
pca_df<-mdf %>% filter(type=="sample")
pr.out <- prcomp(pca_df[,6:(ncol(mdf))], scale. = TRUE)
```

### Scree Plot

```{r}
var_explained_df <- data.frame(PC= as.numeric(paste0(1:150)),
                               var_explained=(pr.out$sdev)^2/sum((pr.out$sdev)^2))

var_explained_df %>%
  ggplot(aes(x=PC,y=var_explained, group=1))+
  geom_point()+
  geom_line()+
  labs(title="Scree plot: PCA on scaled data")

var_explained_df %>%
  ggplot(aes(x=PC,y=var_explained))+
  geom_col()+
  labs(title="Scree plot: PCA on scaled data")

sum(var_explained_df$var_explained[1:11])
```

### Plotting the first 12 PCs since they explain \~65% of the data

```{r}
p1<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 1, y =2)
p2<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 3, y =4)
p3<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 5, y =6)
p4<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 7, y =8)
p5<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 9, y =10)
p6<-autoplot(pr.out, data = pca_df, colour = 'age', shape="batch", size=2, x = 11, y =12)

cowplot::plot_grid(p1,p2,p3,p4,p5,p6)
```

### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```

## Make a Training/Test from the data and try regression on age

```{r}
training_DF <- mdf %>% filter(type == "sample") %>% select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age
```

## Choosing a good model to make the comparisons and storing the RMSE somehow

```{r eval=FALSE, warning=FALSE, include=FALSE}
#Making an empty DF
tunelengths <- data.frame(TrainRMSE = as.numeric(),TrainRsquared = as.numeric(),TrainMAE = as.numeric(),method = as.character(),Name = as.character(),QC = as.character())

#Making a loop to choose the best tunelength (This method could also be applied if I decide to try different models, and I want to compare them)
set.seed(1)
for (i in c(1:15)){
trControl <- trainControl(method = "repeatedcv", number = 10, verboseIter = F, savePredictions = "final")
  
fit1 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = i,
       trControl = trControl,
       metric = 'RMSE'
      )
tunelengths[i-1,] = data.frame(getTrainPerf(fit1), Name = paste0("tunelength", i-1), QC = "none")
}

tunelengths
```

The tuneLength doesn't make the RMSE change much. I will stay with GLMNET and a tunelength of 5.

## Making a simple model and storing the RMSE

```{r}
results <- data.frame(TrainRMSE = as.numeric(),TrainRsquared = as.numeric(),TrainMAE = as.numeric(),method = as.character(),Name = as.character(),QC = as.character())

trControl <- trainControl(method = "repeatedcv", number = 10, repeats=5, verboseIter = F, savePredictions = TRUE)

fit1 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[1,] = data.frame(getTrainPerf(fit1), Name = paste0("fit1"), QC = "none")
```


##Getting the RMSE of each repeat:
https://stackoverflow.com/questions/56950684/how-to-get-predictions-for-each-fold-in-10-fold-cross-validation-of-the-best-tun/56965881#56965881

Looking at the predictions:
```{r}
head(fit1$pred)
```

Getting the predictions with the best alpha and lambda
```{r}
fit1$pred %>%
  filter(alpha == fit1$bestTune$alpha & lambda == fit1$bestTune$lambda) %>% head()
```

Separating the folds and the repeats
```{r}
fit1$pred %>%
  filter(alpha == fit1$bestTune$alpha & lambda == fit1$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% head()
```

Measuring the RMSE
```{r}
error<-fit1$pred %>%
  filter(alpha == fit1$bestTune$alpha & lambda == fit1$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit1")
  

error
```

Size of the dataframe
```{r}

dim(mdf)
```



Visualizing it:
```{r}
error %>% ggplot(aes(x=rep, y=rmse, fill=rep)) +  geom_bar(stat="identity",position=position_stack()) + scale_fill_brewer(palette="Set3") + geom_text(aes(label=round(rmse,4)), position = position_stack(vjust = 0.5))
```




# Model with 4th root transformed data

## 4th root transformation

```{r}
#Imputing zeros
test_df<-mdf %>% gather(key="mz",value="values",6:ncol(mdf))
test_df$values[is.na(test_df$values)] <- 0
#4th root transformation

root_transform <- function(x){
  return (x^0.25)}
mdf[6:(ncol(mdf))] <- lapply(mdf[6:(ncol(mdf))],root_transform)
```

## PCAs for data visualization

```{r}
pca_df<-mdf %>% filter(type=="sample")
pr.out <- prcomp(pca_df[,6:(ncol(mdf))], scale. = TRUE)
```

### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)
test<-data.frame(r$x)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```

## Make a Training/Test from the data and try regression on age

```{r}
training_DF <- mdf %>% filter(type == "sample") %>% select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age
```

## Making the model model and storing the RMSE

```{r}
trControl <- trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = F, savePredictions = "final")

fit2 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[2,] = data.frame(getTrainPerf(fit2), Name = paste0("fit2"), QC = "4th_root")

results
```

## Getting the RMSE for each fold
```{r}
error1<-fit2$pred %>%
  filter(alpha == fit2$bestTune$alpha & lambda == fit2$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit2")

error<-rbind(error,error1)
```

Size of the dataframe
```{r}

dim(mdf)
```


# Model with PCA outliers removed

## Original method using quantiles

I haven't found any package that does it automatically, meaning I will have to explain a bit the theory behind this method. <https://www.r-bloggers.com/2021/09/how-to-remove-outliers-in-r-3/>

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}


bad_rows <- tmp1 %>% filter(n>0)
ms = list()
if (nrow(bad_rows) > 0) {
  ms$values1  <- raw[-bad_rows$rowid,]
  ms$rowinfo1 <- rowinfo[-bad_rows$rowid,]
} else {
  ms$values1  <- raw
  ms$rowinfo1 <- rowinfo
}

#Overwritting the original DF with the new data
values<-ms$values1
rowinfo<-ms$rowinfo1
mdf <- cbind(rowinfo,values)
mdf <- mdf %>% select(-rowid)

ms$rowinfo1 <- ms$rowinfo1 %>% 
  mutate(rowid = row_number()) 

rm(bad_rows, tmp1, tmp2,r)

tmp1 <- ms$rowinfo1 %>% filter(type %in% c("sample"))
tmp2 <- ms$values1[tmp1$rowid,]
plot_pca(tmp1,tmp2,color_label = "age")
rm(tmp1,tmp2)
```

### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)
test<-data.frame(r$x)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```




## Model code

```{r}

training_DF <- mdf %>% filter(type=="sample") %>%  select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age

trControl <- trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = F, savePredictions = "final")

fit3 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[3,] = data.frame(getTrainPerf(fit3), Name = paste0("fit3"), QC = "4th_root + PCA outlier removal")

results
```

## Getting the RMSE for each fold
```{r}
error1<-fit3$pred %>%
  filter(alpha == fit3$bestTune$alpha & lambda == fit3$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit3")

error<-rbind(error,error1)
```

Size of the dataframe
```{r}

dim(mdf)
```


# Model after removing extreme values

## Original method using quantiles to remove features (columns)
(values larger than median + 1.5 \* q90)
```{r}
raw     <- ms$values1
rowinfo <- ms$rowinfo1

tmp1 <- tibble(rowid = rowinfo$rowid, type = rowinfo$type) %>%
  bind_cols(as_tibble(raw))

tmp1 <- tmp1 %>%
  pivot_longer(names_to = "compound", values_to = "value",  cols= c(-rowid, -type))

tmp2 <- tmp1 %>%
 group_by(compound) %>%
 summarise(n_bad = sum(value > median(value)+1.5*quantile(value,0.90))) %>%
 {.}

bad_features <- tmp2 %>%
  ungroup() %>%
  filter(n_bad > 0) %>%
  select(compound) %>%
  distinct()

ms$values2 <- raw %>% select(-any_of(bad_features$compound))
ms$rowinfo2 <- rowinfo

#Overwritting the original DF with the new data
values<-ms$values2
rowinfo<-ms$rowinfo2
mdf <- cbind(rowinfo,values)
mdf <- mdf %>% select(-rowid)

rm(bad_features,tmp2,tmp1,raw)

tmp1 <- ms$rowinfo2 %>% filter(type %in% c("sample"))
tmp2 <- ms$values2[tmp1$rowid,]
plot_pca(tmp1,tmp2,color_label = "age")
```

### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)
test<-data.frame(r$x)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```



## Building the model

```{r}
training_DF <- mdf %>% filter(type=="sample") %>%  select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age

trControl <- trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = F, savePredictions = "final")

fit4 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[4,] = data.frame(getTrainPerf(fit4), Name = paste0("fit4"), QC = "4th_root + PCA outlier removal + Bad features removal")

results
```

## Getting the RMSE for each fold
```{r}
error1<-fit4$pred %>%
  filter(alpha == fit4$bestTune$alpha & lambda == fit4$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit4")

error<-rbind(error,error1)
```

Size of the dataframe
```{r}

dim(mdf)
```


# Model after removing features using QC and blind samples.
```{r}
raw <- ms$values2
rowinfo <- ms$rowinfo2

tmp1 <- rowinfo %>% filter(type %in% c("blind", "qc", "sample")) 
tmp2 <- raw[tmp1$rowid,]

pd1 <- tmp2 %>% 
  bind_cols(tmp1) %>% 
  pivot_longer(starts_with("M")) %>%
  group_by(type, name) %>% 
  summarise(median = median(value), 
            variation = mad(value)/median) %>%
  pivot_wider(names_from = type, values_from=c(median,variation))


good_features <- pd1 %>% 
  filter(median_qc > 1.5*median_blind) %>%
  filter(median_sample > 1.5*median_blind) %>%
  filter(variation_sample > 1.5*variation_qc ) %>%
  filter(variation_sample > 1.5*variation_blind) %>% 
  {.}

ms$rowinfo3 <- rowinfo
ms$values3  <- raw %>% select(any_of(good_features$name))
#Overwriting the original DF with the new data
values<-ms$values3
rowinfo<-ms$rowinfo3
mdf <- cbind(rowinfo,values)
mdf <- mdf %>% select(-rowid)

rm(tmp1,tmp2,pd1,good_features)

tmp1 <- ms$rowinfo3 %>% filter(type %in% c("sample"))
tmp2 <- ms$values3[tmp1$rowid,]
plot_pca(tmp1,tmp2,color_label = "age")
```

### Identifying the possible outliers

```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)
test<-data.frame(r$x)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```



## Making the model

```{r}
training_DF <- mdf %>% filter(type=="sample") %>%  select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age

trControl <- trainControl(method = "repeatedcv", number = 10, repeats = 5, verboseIter = F, savePredictions = "final")

fit5 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[5,] = data.frame(getTrainPerf(fit5), Name = paste0("fit5"), QC = "4th_root + PCA outlier removal + Bad features removal + QC and Bind samples")

results
```

## Getting the RMSE for each fold
```{r}
error1<-fit5$pred %>%
  filter(alpha == fit5$bestTune$alpha & lambda == fit5$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit5")

error<-rbind(error,error1)
```

Size of the dataframe
```{r}

dim(mdf)
```

# Row normalization summing to 1 

## My method
```{r}
View(mdf)

sumofrows<-mdf %>% select(starts_with("M")) %>% rowSums()

test<-mdf %>% mutate(rowsum=sumofrows) %>% 
  select(starts_with("M"), "rowsum")

test<-test/test[,ncol(test)]

mdf <- cbind(rowinfo,test)
mdf <- mdf %>% select(-rowid, -rowsum)
```
## PCA
```{r}
raw     <-  mdf[6:(ncol(mdf))]
rowinfo <- mdf[0:5]
rowinfo <- tibble::rowid_to_column(rowinfo, "rowid")

tmp1 <- rowinfo %>% filter(type %in% c("sample")) %>% mutate(rowid2 = row_number())
tmp2 <- raw[tmp1$rowid,]

r  <- prcomp(x = tmp2, retx = T, center=T, scale. = T, rank. = 12)

bad_rows <- tibble(rowid2=apply(r$x, 2, function(x) {
  which(abs(x - median(x)) > (1.5 * quantile(x,0.95)-quantile(x,0.05))) 
  }) %>%
    unlist() %>% 
    as.vector()) %>% 
    count(rowid2)

tmp1 <- tmp1 %>%
  left_join(bad_rows) %>%
  mutate(n=ifelse(is.na(n), 0,n)) %>%
  mutate(label=ifelse(n>0, rowid, "")) %>%
  {.}

pd <- r$x %>% 
    as_tibble() %>%
    bind_cols(tmp1) %>%
    {.}

pd <- pd %>% 
  mutate(response = ifelse(n>0,"Outlier", "Not outlier")) %>%
  mutate(response = factor(response))

plotlist <- list()

for(i in 1:(ncol(r$x)/2)) {
  xvar <- names(pd)[2*i-1]
  yvar <- names(pd)[2*i]
  p1 <- ggplot(pd,aes(x=!!ensym(xvar), y=!!ensym(yvar), 
                      fill=response, label=label))+
  geom_point(shape=21, color="#FFFFFFFF", size=3) +
  scale_fill_manual(values = c("#D0D0D0", "#D04040")) +
  theme(legend.position="none") +
  NULL
  
  plotlist[[length(plotlist)+1]] <- p1
  rm(p1)
}

cowplot::plot_grid(plotlist = plotlist)
```
## Making the model

```{r}
training_DF <- mdf %>% filter(type=="sample") %>%  select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age

trControl <- trainControl(method = "repeatedcv", number = 10, repeats= 5, verboseIter = F, savePredictions = "final")

fit6 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[6,] = data.frame(getTrainPerf(fit6), Name = paste0("fit6"), QC = "4th_root + PCA outlier removal + Bad features removal + QC and Bind samples + Row Normalization Sum to 1")

results
```

## Getting the RMSE for each fold
```{r}
error1<-fit6$pred %>%
  filter(alpha == fit6$bestTune$alpha & lambda == fit6$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit6")

error<-rbind(error,error1)
```

Size of the dataframe
```{r}

dim(mdf)
```


## Saving the workspace for the BN test:
```{r}
rm(bad_rows,p2,p3,p4,p5,p6,pca_df,pd,plotlist,pr.out,r,raw,rowinfo,test,test_df,tmp1,tmp2,training_DF, training_x, trControl, values, var_explained_df, x)
```


```{r eval=FALSE, include=FALSE}
save.image(file = "data_for_BN.RData")
```




# Robust row normalization (OG method)

```{r eval=FALSE, include=FALSE}
target_info   <- ms$rowinfo3
target_values <- ms$values3 %>% as_tibble()

tmp1 <- target_info %>% filter(type %in% c("qc"))
tmp2 <- target_values[tmp1$rowid,]

stable_features <- tmp1 %>%
  bind_cols(tmp2) %>%
  pivot_longer(starts_with("M")) %>%
  group_by(sample_id) %>%
  mutate(rank=rank(value)) %>%
  ungroup() %>%  
  group_by(name) %>%
  summarise(median = median(rank),
            range = max(rank)-min(rank)) %>%
  ungroup() %>%
  slice_min(order_by = median, prop = 0.8) %>%
  slice_max(order_by = median, prop = 0.8) %>%
  slice_min(order_by = range, prop = 0.8)

raw    <- target_values
data.x <- raw
tmp    <- rowSums(target_values %>% select(any_of(stable_features$name)))
raw    <- max(raw)*raw / tmp

ms$values4  <- raw
ms$rowinfo4 <- target_info

rm(raw,data.x,tmp, stable_features)
rm(target_info, target_values)

tmp1 <- ms$rowinfo4 %>% filter(type %in% c("sample"))
tmp2 <- ms$values4[tmp1$rowid,]
plot_pca(tmp1,tmp2, color_label = "age")

rowinfo<-tmp1
values<-tmp2
mdf <- cbind(rowinfo,values)
mdf <- mdf %>% select(-rowid)

rm(tmp1,tmp2)
```

## Making the model

```{r}
training_DF <- mdf %>% filter(type=="sample") %>%  select(-sample,-batch,-type,-sample_id)
training_DF[is.na(training_DF)] <- 0

training_x <- training_DF %>% select(-age) %>% as.data.frame()
training_y <- training_DF$age

trControl <- trainControl(method = "repeatedcv", number = 10, repeats= 5, verboseIter = F, savePredictions = "final")

fit7 <- train(x = training_x, 
               y = training_y, 
          method = "glmnet",
          tuneLength = 5,
       trControl = trControl,
       metric = 'RMSE'
      )

results[7,] = data.frame(getTrainPerf(fit7), Name = paste0("fit7"), QC = "4th_root + PCA outlier removal + Bad features removal + QC and Bind samples + Row Normalization OG method")

results
```

## Getting the RMSE for each fold
```{r}
error1<-fit7$pred %>%
  filter(alpha == fit6$bestTune$alpha & lambda == fit6$bestTune$lambda) %>% #subset 
  separate(Resample, c("fold", "rep"), "\\.") %>% 
  group_by(rep) %>% #group by replicate
  summarise(rmse = RMSE(obs, pred)) %>% 
  as.data.frame() %>% 
  mutate(model = "fit7")

error<-rbind(error,error1)
```

Size of the dataframe
```{r}
dim(mdf)
```




# Batch normalization using the means
# Plotting the RMSE
```{r}
results %>% ggplot(aes(x=Name, y=TrainRMSE, fill=Name)) +  geom_bar(stat="identity",position=position_stack()) + scale_fill_brewer(palette="Set3") + geom_text(aes(label=round(TrainRMSE,4)), position = position_stack(vjust = 0.5))
```

```{r}
error %>% ggplot(aes(x=rep,y=rmse, fill=rep)) + geom_bar(stat="identity",position=position_stack()) + 
  scale_fill_brewer(palette="Set3") + geom_text(aes(label=round(rmse,4)), position = position_stack(vjust = 0.5)) + 
  facet_wrap(~model)
```

```{r}
error %>% ggplot(aes(x=model,y=rmse, color=model)) + geom_boxplot(outlier.colour = "red") + geom_boxplot(outlier.colour="red", outlier.shape=1,
                outlier.size=8) +
  geom_jitter(shape=16, position=position_jitter(0)) +
  scale_color_brewer(palette="Dark2")
```

